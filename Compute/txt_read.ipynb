{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abab9e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from calc_config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df50d658",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_main, nucleus_name, pathfilename = pathfilename_gen(pcname,input_txt) ### Bug here, run once create folder once, flaw!!\n",
    "os.chdir(abs_main)\n",
    "\n",
    "## Reading the txt file and convert to a list object\n",
    "text_whole = []\n",
    "with open (pathfilename[\"source_text\"], 'rt') as myfile:    \n",
    "    for line in myfile:\n",
    "        line = line.rstrip('\\n')\n",
    "        text_whole.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda0272e",
   "metadata": {},
   "source": [
    "# Parameters extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09ada263",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Extraction of num_particles data; Create a new class of object called num_orbitals\n",
    "## Below the number of particles and orbitals all refer to the valence\"s\n",
    "\n",
    "num_particles = [None,None]\n",
    "\n",
    "## Extract particles number information; Information within the lower bound and upper bound for pairing valence space\n",
    "pattern_energy_start = \"-------------------- Lower bound for Pairing Valence Space -------------------------\"\n",
    "pattern_energy_end   = \"-------------------- Upper bound for Pairing Valence Space -------------------------\"\n",
    "energy_block_id = identify_line(text_whole, pattern_energy_start,pattern_energy_end);\n",
    "energy_block_id.sort()\n",
    "\n",
    "energy_neut_list = text_whole[energy_block_id[0]+1: energy_block_id[1]]\n",
    "energy_prot_list = text_whole[energy_block_id[2]+1: energy_block_id[3]]\n",
    "energy_neut_list = remove_line(energy_neut_list,\"Fermi\")\n",
    "energy_prot_list = remove_line(energy_prot_list,\"Fermi\")\n",
    "\n",
    "num_neut_list = []; num_prot_list = [] ## number of nucleons\n",
    "for line in energy_neut_list:\n",
    "    num_neut_list.append(int(line[53:55]))\n",
    "for line in energy_prot_list:\n",
    "    num_prot_list.append(int(line[53:54]))\n",
    "\n",
    "### Summary of this Block\n",
    "num_particles[0] = sum(num_neut_list); \n",
    "num_particles[1] = sum(num_prot_list); \n",
    "num_particles = tuple(num_particles)\n",
    "### SUMMARY END ###\n",
    "\n",
    "### Getting the hf_lvl index for the lower bound hf states\n",
    "n_start = int(energy_neut_list[0][7:10].strip())\n",
    "p_start = int(energy_prot_list[0][7:10].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "178c69e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop the information of the unbound/continuum states, \n",
    "## for example single particle states with positive energies.\n",
    "unbounded_neut_start = 100; unbounded_prot_start = 100 # state with hf_lvl larger than this will be eliminated\n",
    "for counter, line in enumerate(energy_neut_list):\n",
    "    line = line.replace(')',' ')\n",
    "    line = remove_character(line,'()')\n",
    "    split_list = line.split()\n",
    "    dummy_epsilon = float(split_list[4])\n",
    "    if dummy_epsilon > 0:\n",
    "        unbounded_neut_start = int(split_list[1])\n",
    "        del energy_neut_list[counter:]\n",
    "\n",
    "for counter, line in enumerate(energy_prot_list):\n",
    "    line = line.replace(')',' ')\n",
    "    line = remove_character(line,'()')\n",
    "    split_list = line.split()\n",
    "    dummy_epsilon = float(split_list[4])\n",
    "    if dummy_epsilon > 0:\n",
    "        unbounded_prot_start = int(split_list[1])\n",
    "        del energy_prot_list[counter:]\n",
    "\n",
    "\n",
    "num_orbitals = [None,None]\n",
    "num_spin_orbitals = None\n",
    "\n",
    "## from the above we got the orbitals information; Summary as follows\n",
    "num_neut_orbitals = len(energy_neut_list); num_prot_orbitals = len(energy_prot_list)\n",
    "num_orbitals[0] = num_neut_orbitals; num_orbitals[1] = num_prot_orbitals; num_orbitals = tuple(num_orbitals)\n",
    "num_spin_orbitals = sum(num_orbitals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f62a7c",
   "metadata": {},
   "source": [
    "# Twobody Matrix Terms source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f6d526f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Extract twobody matrix elements information\n",
    "extracted_twobody = []\n",
    "pattern_hf = re.compile(\"HF INDEX AND ISOSPIN\")\n",
    "for line in text_whole:\n",
    "    if pattern_hf.search(line) != None:      # If a match is found\n",
    "        extracted_twobody.append((line.rstrip('\\n')).lstrip('HF INDEX AND ISOSPIN'))\n",
    "### Store the information extracted into a dataframe; and output them as csv for later viewing/assessment\n",
    "obs_twobody_df = pd.DataFrame(columns = [\"q_i1\",\"q_i2\",\"q_f1\",\"q_f2\",\"V_ffii\",\"hf_lvl_i1\",\"iso_i1\",\"hf_lvl_i2\",\"iso_i2\",\"hf_lvl_f1\",\"iso_f1\",\"hf_lvl_f2\",\"iso_f2\"])\n",
    "for counter, extracted_twobody_row in enumerate(extracted_twobody):\n",
    "    row_split = extracted_twobody_row.split()\n",
    "    dummy_q_i1 = np.nan; dummy_q_i2 = np.nan; dummy_q_f2 = np.nan; dummy_q_f2 = np.nan; #q is qubit; i1,i2,f1,and f2  qubit indeces\n",
    "    dummy_V_ffii = float(row_split[8])\n",
    "    dummy_hfl_i1 = int(row_split[0]); dummy_iso_i1 = int(row_split[1])\n",
    "    dummy_hfl_i2 = int(row_split[2]); dummy_iso_i2 = int(row_split[3])\n",
    "    dummy_hfl_f1 = int(row_split[4]); dummy_iso_f1 = int(row_split[5])\n",
    "    dummy_hfl_f2 = int(row_split[6]); dummy_iso_f2 = int(row_split[7])\n",
    "    \n",
    "    ## Skip appending interations involving unbounded states\n",
    "    # remove unbound neutrons\n",
    "    if (((dummy_iso_i1 == 1) and (dummy_hfl_i1 >= unbounded_neut_start)) or\n",
    "        ((dummy_iso_i2 == 1) and (dummy_hfl_i2 >= unbounded_neut_start)) or\n",
    "        ((dummy_iso_f1 == 1) and (dummy_hfl_f1 >= unbounded_neut_start)) or\n",
    "        ((dummy_iso_f2 == 1) and (dummy_hfl_f2 >= unbounded_neut_start))):\n",
    "        continue\n",
    "    # remove unbound protons:\n",
    "    if (((dummy_iso_i1 == 2) and (dummy_hfl_i1 >= unbounded_prot_start)) or\n",
    "        ((dummy_iso_i2 == 2) and (dummy_hfl_i2 >= unbounded_prot_start)) or\n",
    "        ((dummy_iso_f1 == 2) and (dummy_hfl_f1 >= unbounded_prot_start)) or\n",
    "        ((dummy_iso_f2 == 2) and (dummy_hfl_f2 >= unbounded_prot_start))):\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    appending_row = [\n",
    "        dummy_q_i1,dummy_q_i2,dummy_q_f2,dummy_q_f2,dummy_V_ffii,\n",
    "        dummy_hfl_i1,dummy_iso_i1,\n",
    "        dummy_hfl_i2,dummy_iso_i2,\n",
    "        dummy_hfl_f1,dummy_iso_f1,\n",
    "        dummy_hfl_f2,dummy_iso_f2]\n",
    "    obs_twobody_df.loc[counter] = appending_row\n",
    "\n",
    "### Define the qubit indeces\n",
    "#### Start #### create to make the code cleaner, to define the row name for the dataframe and to use them to manipulate the dataframe\n",
    "suffix_list = [\"i1\",\"i2\",\"f1\",\"f2\"]; iso_list=[]; q_list=[]; hf_lvl_list=[]\n",
    "for suffix in suffix_list:\n",
    "    iso_list.append(\"iso_\"+suffix); q_list.append(\"q_\"+suffix); hf_lvl_list.append(\"hf_lvl_\"+suffix)\n",
    "#### End ####\n",
    "for index, row in obs_twobody_df.iterrows():\n",
    "    for (iso_dum,q_dum,hf_lvl_dum) in zip(iso_list, q_list, hf_lvl_list):\n",
    "        if row[iso_dum] == 1:         ## iso = 1 represents neutron; 2 represents proton\n",
    "            row[q_dum] = row[hf_lvl_dum] - n_start\n",
    "        elif row[iso_dum] == 2:\n",
    "            row[q_dum] = row[hf_lvl_dum] - p_start + num_neut_orbitals\n",
    "\n",
    "### To csv\n",
    "obs_twobody_df.reset_index(drop=True,inplace=True)\n",
    "obs_twobody_df.to_csv(pathfilename[\"output_2B-source_csv\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843e6e56",
   "metadata": {},
   "source": [
    "# Onebody Matrix Terms source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b282ef54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract onebody information\n",
    "## Store the onebody terms into panda dataframes and export as csv\n",
    "obs_onebody_df = pd.DataFrame(columns = [\"q_i\",\"spin\",\"epsilon\",\"hf_lvl\",\"iso\"])\n",
    "\n",
    "for counter, line in enumerate(energy_neut_list+energy_prot_list):\n",
    "    dummy_spin = None\n",
    "    dummy_iso = None\n",
    "    dummy_df_row = []\n",
    "    line = line.replace(')',' ')\n",
    "    line = remove_character(line,'()')\n",
    "    split_list = line.split()\n",
    "    if int(split_list[6]) == 1:\n",
    "        dummy_iso = 1\n",
    "    elif int(split_list[6]) == -1:\n",
    "        dummy_iso = 2\n",
    "    else: \n",
    "        pass\n",
    "\n",
    "    if  float(Fraction(split_list[2])) < 0:\n",
    "        dummy_spin = -1\n",
    "    elif float(Fraction(split_list[2])) > 0:\n",
    "        dummy_spin = 1\n",
    "    else:\n",
    "        pass\n",
    "    dummy_hf_lvl = int(split_list[1])\n",
    "    dummy_epsilon = float(split_list[4])\n",
    "    dummy_df_row = [np.nan,dummy_spin,dummy_epsilon,dummy_hf_lvl,dummy_iso]\n",
    "    obs_onebody_df.loc[counter] = dummy_df_row\n",
    "obs_onebody_source_df_output = obs_onebody_df.copy() ## clone the df so that the below codes doesnt mess things up(action is debatable, but i dont care)\n",
    "\n",
    "### Define the qubit indeces for obs_onebody_df (conver hf_lvl to q_i; different encoding/indexing)\n",
    "for index, row in obs_onebody_source_df_output.iterrows():\n",
    "    if row[\"iso\"] == 1:\n",
    "        row[\"q_i\"] = row[\"hf_lvl\"] - n_start\n",
    "    elif row[\"iso\"] == 2:\n",
    "        row[\"q_i\"] = row[\"hf_lvl\"] - p_start + num_orbitals[0]\n",
    "\n",
    "### To csv\n",
    "obs_onebody_source_df_output.to_csv(pathfilename['output_1B-source_csv'])\n",
    "obs_onebody_df = obs_onebody_source_df_output # Change the df back to the changed values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2fc4b0",
   "metadata": {},
   "source": [
    "# Filter out unwanted interactions from obs_twobody_df\n",
    "# Create obs_twobody_H_input_df_output (input for VQE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fe8a0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removal of unbound states wont affect anything here, as the following takes the input of the num_orbitals and num_spin_orbital\n",
    "from itertools import combinations\n",
    "## Create interaction of Interest aka promotion_list\n",
    "### Allowed pair combinations\n",
    "# non_repeat_list = list(combinations(range(0,num_spin_orbitals),2))    ## List pair combination that doesn't repeat same orbitals (particle doesnt occupy same orbital twice)\n",
    "degenerate_levels_list = degenerate_pair_gen(num_orbitals)      ## Degenerate level list, list of pair combinations that share the same energy\n",
    "spin_pair_list = antipara_spin_pair_gen(obs_onebody_df,num_orbitals)  ## list of Pairs with T=1 (include Tz=0,+-1)\n",
    "init_pair_list = HFground_pair_list(num_particles, num_orbitals)      ## Allowed Initial state\n",
    "## to allow for set that include blocked levels for Be9, and set that cater for promotions in Be10\n",
    "\n",
    "neut_state_init = list(range(0,num_particles[0]))\n",
    "prot_state_init = list(range(num_orbitals[0],num_orbitals[0]+num_particles[1]))\n",
    "occupied_state = neut_state_init + prot_state_init\n",
    "\n",
    "allowed_init = list(set(degenerate_levels_list) & set(init_pair_list) & set(spin_pair_list))\n",
    "allowed_fina = [] ; all_fina = list(set(degenerate_levels_list) & set(spin_pair_list))\n",
    "for fina in all_fina: \n",
    "    if (fina[0] in occupied_state) or (fina[1] in occupied_state):\n",
    "        pass\n",
    "    else:\n",
    "        allowed_fina.append(fina)\n",
    "\n",
    "### Allowed promotions\n",
    "#### Neutron orbitals (indeces assigned to qubit)\n",
    "neut_orbitals_list = list(range(0,num_orbitals[0]))\n",
    "#### Proton orbitals (indeces assigned to qubit)\n",
    "prot_orbitals_list = list(range(num_orbitals[0], sum(num_orbitals)))\n",
    "promotion_list = []\n",
    "for init in allowed_init:\n",
    "    promotion_list.append((init,init))\n",
    "    for fina in allowed_fina:\n",
    "        if ((init[0] in neut_orbitals_list) == (fina[0] in neut_orbitals_list) and\n",
    "            (init[1] in neut_orbitals_list) == (fina[1] in neut_orbitals_list) and\n",
    "            (init[0] in prot_orbitals_list) == (fina[0] in prot_orbitals_list) and\n",
    "            (init[1] in prot_orbitals_list) == (fina[1] in prot_orbitals_list)):\n",
    "            excitations = [init,fina]; excitations.sort();\n",
    "            promotion_list.append(tuple(excitations) if (excitations not in promotion_list) else tuple())\n",
    "promotion_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35979bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (0, 8), (1, 9), (8, 9)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allowed_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f544d35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## create a drop_list that containes row index to drop\n",
    "drop_list = []\n",
    "for line_number, (index, row) in enumerate(obs_twobody_df.iterrows()):\n",
    "    init_1 = int(row['q_i1']); init_2 = int(row['q_i2']);\n",
    "    fina_1 = int(row['q_f1']); fina_2 = int(row['q_f2']);\n",
    "    current_promotion = ((init_1,init_2),(fina_1,fina_2))\n",
    "    if (current_promotion in promotion_list):\n",
    "        pass\n",
    "    else:\n",
    "        drop_list.append(line_number)\n",
    "\n",
    "obs_twobody_df.drop(drop_list,axis=0,inplace=True)\n",
    "obs_twobody_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "### To csv\n",
    "obs_twobody_H_input_df_output = obs_twobody_df.copy()\n",
    "obs_twobody_H_input_df_output.to_csv(pathfilename['output_2B-H_input_csv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87a5be7",
   "metadata": {},
   "source": [
    "# Create obs_onebody_H_input_df_output (input for VQE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c76db3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### obs_onebody_df will always be the name of being_worked_df of onebody\n",
    "del obs_onebody_df\n",
    "obs_onebody_df = pd.DataFrame(columns =['q_i','q_f','delta'])\n",
    "\n",
    "### init_fina_list\n",
    "if_list = sin_bod_if_list_gen(num_orbitals)\n",
    "epsilon_list = obs_onebody_source_df_output.loc[:,\"epsilon\"]\n",
    "\n",
    "for counter, if_ in enumerate(if_list):\n",
    "    delta = epsilon_list[if_[1]] - epsilon_list[if_[0]]\n",
    "    obs_onebody_df.loc[counter] = [if_[0], if_[1], round(delta,6)]\n",
    "\n",
    "obs_onebody_H_input_df_output = obs_onebody_df.copy()\n",
    "obs_onebody_H_input_df_output.to_csv(pathfilename['output_1B-H_input_csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a22c2aa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %store promotion_list\n",
    "# %store num_orbitals\n",
    "# %store num_particles\n",
    "# %store num_spin_orbitals\n",
    "# %store obs_onebody_df\n",
    "# %store obs_twobody_df\n",
    "# %store abs_main\n",
    "# %store pathfilename\n",
    "# %store nucleus_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b243af9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
